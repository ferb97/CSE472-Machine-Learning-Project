{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10215483,"sourceType":"datasetVersion","datasetId":6314234},{"sourceId":10215747,"sourceType":"datasetVersion","datasetId":6314460}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import ResNet50, ResNet152, InceptionV3, InceptionResNetV2, Xception, DenseNet121, DenseNet169, DenseNet201\nfrom tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xception_preprocess_input\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nimport math\n\n# Set random seed for reproducibility\nSEED = 42\ntf.random.set_seed(SEED)\n\n# Check GPU availability\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n\n# Directories for training and testing data\ntrain_dir = \"/kaggle/input/skin-lesion-dataset-new/Skin Lesion Input Dataset New/Train_Set_Images\"\ntest_dir = \"/kaggle/input/skin-lesion-dataset-new/Skin Lesion Input Dataset New/Test_Set_Images\"\n\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 64\n\n# Data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=SEED\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Function to build models dynamically\ndef build_model(model_name):\n    if model_name == 'ResNet50':\n        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = resnet_preprocess_input\n    elif model_name == 'ResNet152':\n        base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = resnet_preprocess_input\n    elif model_name == 'InceptionV3':\n        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = inception_preprocess_input\n    elif model_name == 'InceptionResNetV2':\n        base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = inception_preprocess_input\n    elif model_name == 'Xception':\n        base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = xception_preprocess_input\n    elif model_name == 'DenseNet121':\n        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = densenet_preprocess_input\n    elif model_name == 'DenseNet169':\n        base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = densenet_preprocess_input\n    elif model_name == 'DenseNet201':\n        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = densenet_preprocess_input\n\n    \n    # Build the model\n    model = Sequential([\n        base_model,\n        GlobalAveragePooling2D(),\n        Dense(128, activation='relu'),\n        Dropout(0.2),  # Set dropout rate to 0.2\n        Dense(train_generator.num_classes, activation='softmax')\n    ])\n    return model\n\n# List of models to train\nmodels_to_train = ['Xception']\n\n# Training loop\nfor model_name in models_to_train:\n    print(f\"\\nTraining {model_name}...\\n\")\n    model = build_model(model_name)\n\n    # Compile the model\n    optimizer = Adam(learning_rate=0.001)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Learning Rate Scheduler\n    def step_decay(epoch):\n        initial_lr = 0.001\n        drop_rate = 0.1\n        epochs_drop = 5\n        new_lr = initial_lr * math.pow(drop_rate, math.floor((1 + epoch) / epochs_drop))\n        return new_lr\n    \n    lr_scheduler = LearningRateScheduler(step_decay)\n    \n    # Train the model\n    history = model.fit(\n        train_generator,\n        epochs=20,\n        validation_data=test_generator,\n        callbacks=[lr_scheduler],\n        verbose=1\n    )\n\n    # Evaluate the model\n    train_loss, train_acc = model.evaluate(train_generator)\n    test_loss, test_acc = model.evaluate(test_generator)\n\n    print(f\"{model_name} Training Accuracy: {train_acc*100:.2f}%\")\n    print(f\"{model_name} Testing Accuracy: {test_acc*100:.2f}%\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T11:25:11.110148Z","iopub.execute_input":"2024-12-16T11:25:11.110388Z","iopub.status.idle":"2024-12-16T12:31:33.994731Z","shell.execute_reply.started":"2024-12-16T11:25:11.110343Z","shell.execute_reply":"2024-12-16T12:31:33.993962Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\nFound 11438 images belonging to 8 classes.\nFound 2864 images belonging to 8 classes.\n\nTraining Xception...\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734348377.109454     103 service.cc:145] XLA service 0x7d3fa002f070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734348377.109508     103 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1734348377.109512     103 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1734348428.907725     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.5414 - loss: 1.1993 - val_accuracy: 0.3792 - val_loss: 3.2116 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 1s/step - accuracy: 0.7602 - loss: 0.6406 - val_accuracy: 0.6215 - val_loss: 1.1878 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.8234 - loss: 0.4609 - val_accuracy: 0.5964 - val_loss: 1.1476 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.8754 - loss: 0.3502 - val_accuracy: 0.6739 - val_loss: 1.0839 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.9331 - loss: 0.1933 - val_accuracy: 0.8369 - val_loss: 0.5177 - learning_rate: 1.0000e-04\nEpoch 6/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.9808 - loss: 0.0690 - val_accuracy: 0.8439 - val_loss: 0.5578 - learning_rate: 1.0000e-04\nEpoch 7/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9882 - loss: 0.0368 - val_accuracy: 0.8408 - val_loss: 0.6356 - learning_rate: 1.0000e-04\nEpoch 8/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9946 - loss: 0.0183 - val_accuracy: 0.8324 - val_loss: 0.7457 - learning_rate: 1.0000e-04\nEpoch 9/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0085 - val_accuracy: 0.8390 - val_loss: 0.7712 - learning_rate: 1.0000e-04\nEpoch 10/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9980 - loss: 0.0091 - val_accuracy: 0.8425 - val_loss: 0.7541 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.8429 - val_loss: 0.7538 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.8439 - val_loss: 0.7545 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9993 - loss: 0.0038 - val_accuracy: 0.8425 - val_loss: 0.7682 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.8453 - val_loss: 0.7788 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0052 - val_accuracy: 0.8443 - val_loss: 0.7766 - learning_rate: 1.0000e-06\nEpoch 16/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.8446 - val_loss: 0.7742 - learning_rate: 1.0000e-06\nEpoch 17/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0043 - val_accuracy: 0.8436 - val_loss: 0.7770 - learning_rate: 1.0000e-06\nEpoch 18/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.8453 - val_loss: 0.7811 - learning_rate: 1.0000e-06\nEpoch 19/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.8446 - val_loss: 0.7820 - learning_rate: 1.0000e-06\nEpoch 20/20\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.9997 - loss: 0.0039 - val_accuracy: 0.8446 - val_loss: 0.7806 - learning_rate: 1.0000e-07\n\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 273ms/step - accuracy: 1.0000 - loss: 4.3953e-04\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 265ms/step - accuracy: 0.8318 - loss: 0.8237\nXception Training Accuracy: 100.00%\nXception Testing Accuracy: 84.46%\n","output_type":"stream"}],"execution_count":1}]}