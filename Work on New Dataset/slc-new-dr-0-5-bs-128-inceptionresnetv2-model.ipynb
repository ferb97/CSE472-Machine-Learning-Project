{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10215483,"sourceType":"datasetVersion","datasetId":6314234}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import ResNet50, ResNet152, InceptionV3, InceptionResNetV2, Xception, DenseNet121, DenseNet169, DenseNet201\nfrom tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input as xception_preprocess_input\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess_input\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nimport math\n\n# Set random seed for reproducibility\nSEED = 42\ntf.random.set_seed(SEED)\n\n# Check GPU availability\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n\n# Directories for training and testing data\ntrain_dir = \"/kaggle/input/skin-lesion-input-dataset-new/Skin Lesion Input Dataset New/Train_Set_Images\"\ntest_dir = \"/kaggle/input/skin-lesion-input-dataset-new/Skin Lesion Input Dataset New/Test_Set_Images\"\n\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 128\n\n# Data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=SEED\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Function to build models dynamically\ndef build_model(model_name):\n    if model_name == 'ResNet50':\n        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = resnet_preprocess_input\n    elif model_name == 'ResNet152':\n        base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = resnet_preprocess_input\n    elif model_name == 'InceptionV3':\n        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = inception_preprocess_input\n    elif model_name == 'InceptionResNetV2':\n        base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = inception_preprocess_input\n    elif model_name == 'Xception':\n        base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = xception_preprocess_input\n    elif model_name == 'DenseNet121':\n        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = densenet_preprocess_input\n    elif model_name == 'DenseNet169':\n        base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = densenet_preprocess_input\n    elif model_name == 'DenseNet201':\n        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n        preprocess_func = densenet_preprocess_input\n\n    \n    # Build the model\n    model = Sequential([\n        base_model,\n        GlobalAveragePooling2D(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),  # Set dropout rate to 0.2\n        Dense(train_generator.num_classes, activation='softmax')\n    ])\n    return model\n\n# List of models to train\nmodels_to_train = ['InceptionResNetV2']\n\n# Training loop\nfor model_name in models_to_train:\n    print(f\"\\nTraining {model_name}...\\n\")\n    model = build_model(model_name)\n\n    # Compile the model\n    optimizer = Adam(learning_rate=0.001)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    # Learning Rate Scheduler\n    def step_decay(epoch):\n        initial_lr = 0.001\n        drop_rate = 0.1\n        epochs_drop = 5\n        new_lr = initial_lr * math.pow(drop_rate, math.floor((1 + epoch) / epochs_drop))\n        return new_lr\n    \n    lr_scheduler = LearningRateScheduler(step_decay)\n    \n    # Train the model\n    history = model.fit(\n        train_generator,\n        epochs=20,\n        validation_data=test_generator,\n        callbacks=[lr_scheduler],\n        verbose=1\n    )\n\n    # Evaluate the model\n    train_loss, train_acc = model.evaluate(train_generator)\n    test_loss, test_acc = model.evaluate(test_generator)\n\n    print(f\"{model_name} Training Accuracy: {train_acc*100:.2f}%\")\n    print(f\"{model_name} Testing Accuracy: {test_acc*100:.2f}%\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:53:50.763984Z","iopub.execute_input":"2024-12-16T10:53:50.764467Z","iopub.status.idle":"2024-12-16T12:11:03.559271Z","shell.execute_reply.started":"2024-12-16T10:53:50.764430Z","shell.execute_reply":"2024-12-16T12:11:03.558490Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\nFound 11438 images belonging to 8 classes.\nFound 2864 images belonging to 8 classes.\n\nTraining InceptionResNetV2...\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m219055592/219055592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734346540.370489     103 service.cc:145] XLA service 0x7ab7cc0269e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734346540.370547     103 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1734346540.370554     103 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734346669.120859     103 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_104', 72 bytes spill stores, 72 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_103', 128 bytes spill stores, 128 bytes spill loads\n\nI0000 00:00:1734346669.241070     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m89/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4617 - loss: 1.4524","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1734346956.563180     103 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_105', 72 bytes spill stores, 72 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_104', 128 bytes spill stores, 128 bytes spill loads\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 4s/step - accuracy: 0.4641 - loss: 1.4459 - val_accuracy: 0.2451 - val_loss: 4.1157 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.7140 - loss: 0.7676 - val_accuracy: 0.4640 - val_loss: 1.6421 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.7883 - loss: 0.5737 - val_accuracy: 0.2577 - val_loss: 4.1546 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.8422 - loss: 0.4449 - val_accuracy: 0.4836 - val_loss: 2.4345 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.8935 - loss: 0.2923 - val_accuracy: 0.7821 - val_loss: 0.6262 - learning_rate: 1.0000e-04\nEpoch 6/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9523 - loss: 0.1429 - val_accuracy: 0.8055 - val_loss: 0.5964 - learning_rate: 1.0000e-04\nEpoch 7/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.9763 - loss: 0.0766 - val_accuracy: 0.8198 - val_loss: 0.6909 - learning_rate: 1.0000e-04\nEpoch 8/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.9931 - loss: 0.0274 - val_accuracy: 0.8198 - val_loss: 0.9611 - learning_rate: 1.0000e-04\nEpoch 10/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9959 - loss: 0.0159 - val_accuracy: 0.8310 - val_loss: 0.9292 - learning_rate: 1.0000e-05\nEpoch 11/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.9978 - loss: 0.0122 - val_accuracy: 0.8317 - val_loss: 0.9204 - learning_rate: 1.0000e-05\nEpoch 12/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.9989 - loss: 0.0094 - val_accuracy: 0.8307 - val_loss: 0.9385 - learning_rate: 1.0000e-05\nEpoch 13/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0079 - val_accuracy: 0.8314 - val_loss: 0.9530 - learning_rate: 1.0000e-05\nEpoch 14/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.8307 - val_loss: 0.9682 - learning_rate: 1.0000e-05\nEpoch 15/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9987 - loss: 0.0082 - val_accuracy: 0.8303 - val_loss: 0.9705 - learning_rate: 1.0000e-06\nEpoch 16/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.9993 - loss: 0.0070 - val_accuracy: 0.8314 - val_loss: 0.9706 - learning_rate: 1.0000e-06\nEpoch 17/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9985 - loss: 0.0084 - val_accuracy: 0.8317 - val_loss: 0.9723 - learning_rate: 1.0000e-06\nEpoch 18/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0093 - val_accuracy: 0.8310 - val_loss: 0.9737 - learning_rate: 1.0000e-06\nEpoch 19/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9991 - loss: 0.0074 - val_accuracy: 0.8321 - val_loss: 0.9741 - learning_rate: 1.0000e-06\nEpoch 20/20\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0068 - val_accuracy: 0.8317 - val_loss: 0.9747 - learning_rate: 1.0000e-07\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 651ms/step - accuracy: 1.0000 - loss: 7.1457e-04\n\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 584ms/step - accuracy: 0.8260 - loss: 1.0017\nInceptionResNetV2 Training Accuracy: 100.00%\nInceptionResNetV2 Testing Accuracy: 83.17%\n","output_type":"stream"}],"execution_count":1}]}